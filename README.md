# Real-Time AI Tutor â€” Sketchpad

A product-ready **proofâ€‘ofâ€‘concept** that teaches in real time using a collaborative sketchpad. The AI tutor chats with the learner and **sketches stepâ€‘byâ€‘step** on a shared canvas, synchronized with its explanation.

> **Timebox assumed:** ~36 hours (within the requested â€œ24â€“48 hoursâ€).

https://github.com/yourname/ai-tutor-sketchpad (put your repo here after pushing)

---

## âœ¨ Features

- **Real-time conversation** via WebSockets
- **Synchronized sketching**: the tutor draws primitives (lines/rects/circles/polyline) step-by-step while speaking
- **Low-latency streaming** of tokens to the chat UI for a â€œlive thinkingâ€ feel
- **Interactive sketchpad**: learner can draw with color + width, Clear, and Save PNG
- **Optional voice** output in the browser with the Web Speech API
- **No API keys required for the demo** â€” ships with a scripted lesson on the **Pythagorean theorem**

---

## ğŸ§ª Quickstart

> Requires Python 3.10+

```bash
# 1) Clone and enter
git clone https://github.com/yourname/ai-tutor-sketchpad.git
cd ai-tutor-sketchpad

# 2) Install deps
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt

# 3) Run
uvicorn main:app --reload

# 4) Open
# Visit http://localhost:8000 in your browser
```

**Demo tip:** Click **â€œDemo Promptâ€** or ask: `Explain the Pythagorean theorem` to see the synchronized sketching.

---

## ğŸ§± Architecture & Design Choices

### High level
```mermaid
flowchart LR
    U[User Browser] <-- WebSocket --> S[FastAPI Server]
    U -- Canvas events --> U
    U -->|HTTP| Static[Static Files (HTML/CSS/JS)]
    S -. Orchestrator .-> LLM[(LLM: optional)]
```

- **Frontend:** Plain HTML/CSS/JS to keep the POC lightweight and easy to run. A singleâ€‘page app manages chat, streaming tokens, and an HTML5 canvas sketchpad.
- **Backend:** FastAPI with WebSockets for **lowâ€‘latency** biâ€‘directional messaging. One endpoint `/ws` drives chat and drawing.
- **AI Orchestrator:** For reliability without external keys, the demo uses a **scripted teaching plan** for the Pythagorean theorem that emits a mixed stream of **chat tokens** and **drawing commands**. You can swap this with any LLM that emits the same event protocol.

### Event protocol (server â†’ client)
```jsonc
{ "type": "chat_token",   "token": "streamed token ..." }
{ "type": "chat_message", "message": "final sentence" }
{ "type": "draw", "cmd": "clear" }
{ "type": "draw", "cmd": "line", "args": {"x1":120,"y1":380,"x2":520,"y2":380}, "style": {"color":"#222","width":3} }
{ "type": "draw", "cmd": "rect", "args": {"x":120,"y":380,"w":400,"h":140}, "style": {"color":"#5a9cff","width":2} }
{ "type": "draw", "cmd": "circle", "args": {"x":200,"y":200,"r":40}, "style": {"color":"#aaa","width":2} }
{ "type": "draw", "cmd": "polyline", "args": {"points":[{"x":..,"y":..}, ...], "closed": true}, "style": {"color":"#ff8a00","width":2} }
{ "type": "draw", "cmd": "text", "args": {"x":330,"y":240,"text":"cÂ²"}, "style": {"color":"#ff8a00","width":2} }
```

### Why WebSockets?
- Biâ€‘directional, lowâ€‘latency streaming for both **chat tokens** and **drawing** commands.
- Clean separation of concerns: the **orchestrator** yields an interleaved sequence; the frontend renders it in order.

### Scalability & robustness
- FastAPIâ€™s event loop handles multiple sessions concurrently; upgrade by running with **Uvicorn + workers** behind **NGINX**.
- Protocol is **modelâ€‘agnostic**: switch to OpenAI/Gemini/Llama or a local model emitting the same events.
- Add **room IDs** or session routing to support classrooms; persist drawings per room if needed.

---

## ğŸ”Œ Optional LLM Integration

This POC ships with a deterministic Pythagorean lesson. To plug an LLM:
1. Replace `generate_events_for_query()` in `main.py` to call your model.
2. Parse your model output into the same event protocol:
   - Stream `chat_token` tokens as they arrive.
   - Emit `draw` commands (line/rect/circle/polyline/text) as the model â€œdecidesâ€ to sketch.
3. Consider a **â€œtool useâ€** prompt format where the LLM returns JSON drawing actions.

> Tip: Keep drawing **stepâ€‘wise** with small time gaps (e.g., 50â€“150 ms) so it feels natural.

---

## ğŸ–Šï¸ Sketchpad Features

- Lines, rectangles, circles, polylines, and text annotations
- Change **stroke color** & **width**
- **Clear** canvas
- **Save PNG** of the current board
- User can draw freely; AIâ€™s drawing arrives over the socket

---

## ğŸ“ Chosen Concept: *Pythagorean Theorem*

The demo draws a **right triangle**, labels **a, b, c**, then constructs squares on the two legs and a tilted square on the hypotenuse. The narration and sketch are synchronized to reinforce **aÂ² + bÂ² = cÂ²**.

**Try:** â€œExplain the Pythagorean theorem with a diagram.â€

---

## ğŸ“ Project Structure

```
ai-tutor-sketchpad/
â”œâ”€ main.py                # FastAPI + WebSocket backend
â”œâ”€ requirements.txt
â”œâ”€ public/
â”‚  â”œâ”€ index.html          # SPA: chat + canvas UI
â”‚  â”œâ”€ styles.css          # clean, modern UI
â”‚  â””â”€ script.js           # socket, drawing primitives, voice
â””â”€ README.md
```

---

## ğŸ§° Commands

- **Run dev server:** `uvicorn main:app --reload`
- **Change port:** `uvicorn main:app --host 0.0.0.0 --port 8080`
- **Production thinking:** run behind NGINX; scale with multiple Uvicorn workers.

---

## ğŸ§ª Demo Guide (prompts)

- â€œExplain the **Pythagorean theorem** with a diagram.â€ âœ… (triggers sketch)
- Ask anything else; the tutor will suggest the Pythagorean demo.

---

## ğŸ”’ Assumptions

- Timebox 36 hours for design, build, and polish.
- No external API keys required for the core demo.
- Browser supports Web Speech API (voice is optional and can be toggled).

---

## ğŸ“¸ Screenshots / Video (optional)

- Include short 30â€“120s screen recording of the interaction when you publish the repo.

---

## ğŸ“ License

MIT
